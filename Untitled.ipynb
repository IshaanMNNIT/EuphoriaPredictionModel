{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a7f664-5970-45c7-a4b5-0a54aa020bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device for prediction: cuda\n",
      "\n",
      "Submission file 'submission_nn_binary.csv' created successfully.\n",
      "\n",
      "First 5 rows:\n",
      "      id    Target\n",
      "0  35956  0.123399\n",
      "1  60927  0.222833\n",
      "2  79918  0.325785\n",
      "3  50078  0.106976\n",
      "4  44080  0.049657\n",
      "\n",
      "Total predictions: 38670\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. PyTorch Components ---\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else \n",
    "                      'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device for prediction: {DEVICE}\")\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, features):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx]\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.layer_stack(x))\n",
    "\n",
    "# --- 2. Preprocessing Function ---\n",
    "\n",
    "def preprocess_data(df, scaler=None, fit_scaler=False, all_train_columns=None):\n",
    "    df_clean = df.copy()\n",
    "    df_clean.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    X = df_clean.drop(['id', 'Y'] if 'Y' in df_clean.columns else ['id'], axis=1)\n",
    "    \n",
    "    # --- Missing indicators ---\n",
    "    if fit_scaler:\n",
    "        cols_with_nan = X.columns[X.isnull().sum() > 0].tolist()\n",
    "    else:\n",
    "        # Use only the train NaN columns that exist in test\n",
    "        cols_with_nan = [col for col in all_train_columns if col in X.columns and '_nan' not in col]\n",
    "    \n",
    "    for col in cols_with_nan:\n",
    "        X[f'{col}_nan'] = X[col].isnull().astype(int)\n",
    "\n",
    "    # --- Log transform ---\n",
    "    log_transform_cols = ['x_9', 'x_10', 'x_12', 'x_13']\n",
    "    for col in log_transform_cols:\n",
    "        if col in X.columns:\n",
    "            X[col] = np.log1p(X[col].abs())\n",
    "\n",
    "    # --- Median Imputation ---\n",
    "    X_imputed = X.fillna(X.median())\n",
    "\n",
    "    # --- Ensure columns match training set ---\n",
    "    if not fit_scaler and all_train_columns is not None:\n",
    "        X_imputed = X_imputed.reindex(columns=all_train_columns, fill_value=0)\n",
    "\n",
    "    # --- Scaling ---\n",
    "    if fit_scaler:\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_imputed)\n",
    "        return X_scaled, scaler, X_imputed.columns.tolist()\n",
    "    else:\n",
    "        X_scaled = scaler.transform(X_imputed)\n",
    "        return X_scaled\n",
    "\n",
    "# --- 3. Main Prediction & Submission Function ---\n",
    "\n",
    "def create_nn_submission(train_file='train.csv', test_file='test.csv', model_path='best_mlp_model.pth'):\n",
    "    # Load datasets\n",
    "    df_train = pd.read_csv(train_file)\n",
    "    df_test = pd.read_csv(test_file)\n",
    "\n",
    "    # --- Train Data Prep ---\n",
    "    X_train_scaled, scaler, train_columns = preprocess_data(df_train, fit_scaler=True)\n",
    "\n",
    "    # --- Test Data Prep ---\n",
    "    X_test_scaled = preprocess_data(df_test, scaler=scaler, fit_scaler=False, all_train_columns=train_columns)\n",
    "\n",
    "    # --- Load Model ---\n",
    "    try:\n",
    "        input_size = X_test_scaled.shape[1]\n",
    "        model = MLP(input_size).to(DEVICE)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "        model.eval()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Model file '{model_path}' not found.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR loading model: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- Dataset & Predictions ---\n",
    "    test_dataset = TabularDataset(X_test_scaled)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    test_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(DEVICE)\n",
    "            outputs = model(X_batch)\n",
    "            test_predictions.extend(outputs.cpu().numpy().flatten())\n",
    "\n",
    "    # --- Apply Binary Threshold ---\n",
    "    test_pred_binary = (np.array(test_predictions) > 0.5).astype(int)\n",
    "\n",
    "    # --- Save Submission ---\n",
    "    submission = pd.DataFrame({\n",
    "        'id': df_test['id'],\n",
    "        'Target': test_predictions\n",
    "    })\n",
    "\n",
    "    submission_filename = 'submission_nn_binary.csv'\n",
    "    submission.to_csv(submission_filename, index=False)\n",
    "\n",
    "    print(f\"\\nSubmission file '{submission_filename}' created successfully.\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(submission.head())\n",
    "    print(f\"\\nTotal predictions: {len(submission)}\")\n",
    "\n",
    "# --- Execute ---\n",
    "if __name__ == '__main__':\n",
    "    create_nn_submission()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fec075-7697-4076-9a39-6677c1151f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch_env)",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
