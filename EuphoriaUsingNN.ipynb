{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51c4c78e-8228-47eb-bfde-f8d307f21387",
   "metadata": {},
   "source": [
    "##### x_9,x_10,x_12,x_13 show data heavily compressed near zero, with long tails extending to extremely large values (confirming the 10 20 order seen in the initial inspection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353a6657-036c-40bf-8979-e16f2c703e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "  -> NEW GLOBAL BEST AUC: 0.7699 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7784 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7807 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7827 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7841 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7851 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7855 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7862 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7867 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7869 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7873 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7879 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7880 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7881 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7886 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7888 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7889 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7892 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7894 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7900 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7901 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7902 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7906 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7907 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7907 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7909 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7911 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7912 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7914 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7916 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7917 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7919 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7920 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7921 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7922 (Saved model state)\n",
      "  -> NEW GLOBAL BEST AUC: 0.7923 (Saved model state)\n",
      "  -> Early stopping at epoch 100. Best AUC: 0.7923\n",
      "\n",
      "--- Starting Fold 2/5 ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Configuration and Data Loading ---\n",
    "\n",
    "# Check for GPU (CUDA/MPS)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "try:\n",
    "    df_train = pd.read_csv('train.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'train.csv' not found.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. PyTorch Components (MLP Architecture) ---\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.float32).unsqueeze(1)\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 128), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32), nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.layer_stack(x))\n",
    "\n",
    "# --- 3. Preprocessing Pipeline ---\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Handles cleaning, feature engineering, scaling, and returns arrays.\"\"\"\n",
    "    df_clean = df.copy()\n",
    "    df_clean['Y'] = df_clean['Y'].astype(int)\n",
    "    df_clean.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    X = df_clean.drop(['id', 'Y'], axis=1)\n",
    "\n",
    "    # Feature Engineering\n",
    "    cols_with_nan = X.columns[X.isnull().sum() > 0].tolist()\n",
    "    for col in cols_with_nan:\n",
    "        X[f'{col}_nan'] = X[col].isnull().astype(int)\n",
    "    log_transform_cols = ['x_9', 'x_10', 'x_12', 'x_13']\n",
    "    for col in log_transform_cols:\n",
    "        X[col] = np.log1p(X[col].abs()) \n",
    "\n",
    "    # Imputation\n",
    "    median_values = X.median()\n",
    "    X_imputed = X.fillna(median_values)\n",
    "\n",
    "    # Scaling (MANDATORY for NNs)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_imputed)\n",
    "    \n",
    "    return X_scaled, df_clean['Y'].values, scaler\n",
    "\n",
    "# --- 4. Training and Saving Logic ---\n",
    "\n",
    "def train_and_save_model(X, y, scaler, epochs=100, batch_size=64, learning_rate=1e-4):\n",
    "    \"\"\"Performs CV and saves the model with the highest validation AUC.\"\"\"\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    overall_best_auc = 0\n",
    "    \n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "        print(f\"\\n--- Starting Fold {fold+1}/5 ---\")\n",
    "        \n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        train_dataset = TabularDataset(X_train, y_train)\n",
    "        val_dataset = TabularDataset(X_val, y_val)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize model for THIS fold\n",
    "        model = MLP(X.shape[1]).to(DEVICE)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        fold_best_auc = 0\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Training\n",
    "            model.train()\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(model(X_batch), y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_targets, val_predictions = [], []\n",
    "            with torch.no_grad():\n",
    "                for X_batch, y_batch in val_loader:\n",
    "                    X_batch = X_batch.to(DEVICE)\n",
    "                    outputs = model(X_batch)\n",
    "                    val_predictions.extend(outputs.cpu().numpy().flatten())\n",
    "                    val_targets.extend(y_batch.cpu().numpy().flatten())\n",
    "\n",
    "            val_auc = roc_auc_score(val_targets, val_predictions)\n",
    "            \n",
    "            # --- MODEL SAVING LOGIC ---\n",
    "            if val_auc > fold_best_auc:\n",
    "                fold_best_auc = val_auc\n",
    "                patience_counter = 0\n",
    "                \n",
    "                # Check if this fold's best score is the overall best\n",
    "                if fold_best_auc > overall_best_auc:\n",
    "                    overall_best_auc = fold_best_auc\n",
    "                    # **THIS IS WHERE THE MODEL IS SAVED**\n",
    "                    torch.save(model.state_dict(), 'best_mlp_model.pth')\n",
    "                    print(f\"  -> NEW GLOBAL BEST AUC: {overall_best_auc:.4f} (Saved model state)\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= 15: # Early stopping patience\n",
    "                    print(f\"  -> Early stopping at epoch {epoch+1}. Best AUC: {fold_best_auc:.4f}\")\n",
    "                    break\n",
    "        \n",
    "    print(\"\\n====================================\")\n",
    "    print(f\"Training Complete. FINAL BEST AUC-ROC saved: {overall_best_auc:.4f}\")\n",
    "    print(\"====================================\")\n",
    "    \n",
    "    return overall_best_auc, scaler\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == '__main__':\n",
    "    # 1. Preprocess Data\n",
    "    X_scaled, y, scaler = preprocess_data(df_train)\n",
    "    \n",
    "    # 2. Train and Save Model\n",
    "    # This function will generate 'best_mlp_model.pth'\n",
    "    train_and_save_model(X_scaled, y, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a54906b-f1b4-4bd3-910a-928ed56fa68a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch_env)",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
